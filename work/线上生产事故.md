# 线上生产事故

## 多线程多事务导致死等待

类似两阶段提交的方案就会产生问题，1.主线程认为可以提交的时候，子线程部分挂了。2.如果线程数设置不合理，那么可能导致5个线程 4个线程执行完了阻塞了，还有一个线程在线程池的等待队列中，而4个线程又不会释放。

多线程多个事务之间的死锁

问题：线程A 使用id in 语句来更新多个id的数据，但是由于id的不连续性，该更新sql锁住整个表，执行完sql后该线程睡眠 等待唤醒

线程B 插入语句 因为和线程A不同的事务，所以会等待线程A的表锁释放才能进行插入数据操作，而此刻线程A处于睡眠等待，造成死锁。

优化：

1. 多线程使用同一个事务  遭遇慢sql可能还是会卡 不太推荐

2. 批量插入使用 insert into dbo.xxx values () ()
3. 可以全部不采用事务，将多个sql的更新结果记录日志，记录到单独的日志文件中，因为出错是极少的情况，一旦出错可以利用日志进行数据补偿来继续走下去
4. 拆分成多个事务，将速度快的事务先执行，速度慢的事务采用日志记录+单独事务执行的方式，出错可补救
5. 定时任务分片，将数据切片分发给多个机器，每个机器上操作一个分片的数据，只更新单个学校的数据整体，出错修复单个学校以及后续学校所有要操作的数据即可



## 多线程查询

多线程查询的性能虽然可以改善单个请求的时长，但是整体机器的资源是有限的，在整体的性能上并不能提升，相反还会降低机器的一定并发性能，多个线程的查询由于多个sql查询的请求，也会增大数据库节点的请求处理压力，且在线程池内，如果在执行的任务睡眠等待，而还有的任务处于任务等待队列中，那么会造成线程池的死等待。



## 分片未排序导致节点处理数据重复

xxl-job集群分片处理数据时，未对数据进行排序，导致在有join语句参与的sql结果返回乱序，数据切分混乱，节点间处理了重复数据。



### 大数据量下的定时任务集群分片

1.采用先按照集群进行分片，每片数据再做当前节点分页。

2.各节点整体进行分页，将每页的ID%index 确定当前节点要处理的数据，再回查全部字段进行业务处理。

这样是为了避免在数据库端进行id%index的操作，减少数据库压力，将压力转移到业务服务器。

![](.\images\images01.png)



**多节点处理数据时，不能保证同一时间点完成**

1.整体数据要么各司其职，在当前节点处理完所有业务逻辑。

2.否则独立出一个定时任务来做后续的整体处理，否则在A节点处理完成数据开始执行善后处理时，B节点可能还在对善后处理的数据进行操作。

例如：

![image-20241210141751694](.\images\image-20241210141751694.png)





## 线上close_wait状态的socket大量出现和大量wait状态线程

线上突发卡顿，出现了大量的wait状态的线程，排查发现有大量的close_wait状态的socket存在，其中90%指向阿里云oss的ip地址，怀疑阿里云oss文件流资源未释放

通过打印线程堆栈文件，发现oss线程大部分被parking在线程池中，确定oss的socket连接池满导致线程获取不到连接，阻塞在锁上等待。

排查系统中所有用到oss的上传下载代码，发现通用下载接口中存在oss流开启但未关闭的情况，关闭后系统的close_wait状态socket数量下降，系统稳定。

核心是oss的这里，针对要文件流的请求，并不会进行关闭，keepResponseOpen状态为true，其他请求会自动关闭

![image-20251017143053678](D:\doc\my\studymd\LearningNotes\work\images\image-20251017143053678.png)



oss内部使用了apache的`PoolingHttpClientConnectionManager`，内部针对连接进行了池化和复用，当同一个目标地址的请求达到限制，就会使得后续的线程等待，造成大量的tomcat线程wait状态

![image-20251017143233155](D:\doc\my\studymd\LearningNotes\work\images\image-20251017143233155.png)







## 其他知识

**sqlserver不支持使用insert批量插入返回主键id，mysql支持**

SELECT SCOPE_IDENTITY() AS NewID;

